{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d59189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as functional_model\n",
    "\n",
    "# Suppress an irritating warning with pandas\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fba8007",
   "metadata": {},
   "source": [
    "### Data, Model, and Evaluation ###\n",
    "\n",
    "The data used was the \"breast-cancer-wisconsin.data\" from the UCI url provided.\n",
    "This set included 11 columns, including ID number and diagnosis.\n",
    "\n",
    "The model is a simple linear binary classifier, using less than 300 epochs and a learning rate of 0.01.\n",
    "I noticed slghtly worse predictions using \"mean\" for the loss function rather than \"sum\"\n",
    "I still got over 98% with mean, but sum would often hit 100%\n",
    "The model was run using a CUDA capable Nvidia card.\n",
    "\n",
    "For evaluation, I used sklearn's train_test_split to get test and train sets\n",
    "As the model uses a sigmoid, the test set is tested for greather than 0.5, returning an np array of boolean values\n",
    "The model, with the current hyperparameters, was getting a 98% to 100% accuracy with a train-test of 10% with random state 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8baf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers names taken directly from the \"breast_cancer_wisconsin.names\" file\n",
    "\n",
    "data = pd.read_csv(\"bcw.data\", names=[\"id_number\",\n",
    "                                     \"Clump_Thickness\",\n",
    "                                     \"Uniformity_of_Cell Size\",\n",
    "                                     \"Uniformity_of_Cell Shape\",\n",
    "                                     \"Marginal_Adhesion\",\n",
    "                                     \"Single_Epithelial_Cell_Size\",\n",
    "                                     \"Bare_Nuclei\",\n",
    "                                     \"Bland_Chromatin\",\n",
    "                                     \"Normal_Nucleoli\",\n",
    "                                     \"Mitoses\",\n",
    "                                     \"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175322cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell Size</th>\n",
       "      <th>Uniformity_of_Cell Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_number  Clump_Thickness  Uniformity_of_Cell Size  \\\n",
       "0      1000025                5                        1   \n",
       "1      1002945                5                        4   \n",
       "2      1015425                3                        1   \n",
       "3      1016277                6                        8   \n",
       "4      1017023                4                        1   \n",
       "..         ...              ...                      ...   \n",
       "694     776715                3                        1   \n",
       "695     841769                2                        1   \n",
       "696     888820                5                       10   \n",
       "697     897471                4                        8   \n",
       "698     897471                4                        8   \n",
       "\n",
       "     Uniformity_of_Cell Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "694                         1                  1                            3   \n",
       "695                         1                  1                            2   \n",
       "696                        10                  3                            7   \n",
       "697                         6                  4                            3   \n",
       "698                         8                  5                            4   \n",
       "\n",
       "    Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "0             1                3                1        1      2  \n",
       "1            10                3                2        1      2  \n",
       "2             2                3                1        1      2  \n",
       "3             4                3                7        1      2  \n",
       "4             1                3                1        1      2  \n",
       "..          ...              ...              ...      ...    ...  \n",
       "694           2                1                1        1      2  \n",
       "695           1                1                1        1      2  \n",
       "696           3                8               10        2      4  \n",
       "697           4               10                6        1      4  \n",
       "698           5               10                4        1      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48aa795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<AxesSubplot:title={'center':'id_number'}>\n",
      "  <AxesSubplot:title={'center':'Clump_Thickness'}>\n",
      "  <AxesSubplot:title={'center':'Uniformity_of_Cell Size'}>]\n",
      " [<AxesSubplot:title={'center':'Uniformity_of_Cell Shape'}>\n",
      "  <AxesSubplot:title={'center':'Marginal_Adhesion'}>\n",
      "  <AxesSubplot:title={'center':'Single_Epithelial_Cell_Size'}>]\n",
      " [<AxesSubplot:title={'center':'Bland_Chromatin'}>\n",
      "  <AxesSubplot:title={'center':'Normal_Nucleoli'}>\n",
      "  <AxesSubplot:title={'center':'Mitoses'}>]\n",
      " [<AxesSubplot:title={'center':'Class'}> <AxesSubplot:> <AxesSubplot:>]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are many long tails and outliers with the feature distributions, so I will use sklearn's StandardScalar to soften them\n",
    "print(data.hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8eba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to get the encoder to change the diagnosis \"Class\" from 2s and 4s to 0s and 1s\n",
    "scalar = StandardScaler()\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e46ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     402\n",
       "10    132\n",
       "2      30\n",
       "5      30\n",
       "3      28\n",
       "8      21\n",
       "4      19\n",
       "?      16\n",
       "9       9\n",
       "7       8\n",
       "6       4\n",
       "Name: Bare_Nuclei, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Note that there are 16 instances of '?' in this column.\n",
    "According to the .names file, these are instances of missing data.\n",
    "As a result, I am going to filter out these rows.\n",
    "'''\n",
    "\n",
    "data[\"Bare_Nuclei\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32083b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.Bare_Nuclei != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0ba5f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     402\n",
       "10    132\n",
       "2      30\n",
       "5      30\n",
       "3      28\n",
       "8      21\n",
       "4      19\n",
       "9       9\n",
       "7       8\n",
       "6       4\n",
       "Name: Bare_Nuclei, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Bare_Nuclei\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b06ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data.drop(columns=[\"id_number\", \"Class\"])\n",
    "y_raw = data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa6ec0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nparray = X_raw.to_numpy()\n",
    "X_nparray = X_nparray.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de7fca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = np.array(encoder.fit_transform(y_raw))\n",
    "X_scaled = scalar.fit_transform(X_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbb5a016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209ae849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5184da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36138a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make each of the splits into tensors\n",
    "\n",
    "X_train_torch = Variable(torch.from_numpy(X_train))\n",
    "y_train_torch = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "X_test_torch = Variable(torch.from_numpy(X_test))\n",
    "y_test_torch = Variable(torch.from_numpy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c60ef95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct class for linear classifier neural network\n",
    "class Linear_nn(torch.nn.Module):\n",
    "    \n",
    "    # Constructor class\n",
    "    def __init__(self):\n",
    "        super(Linear_nn, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(9, 6)\n",
    "        self.l2 = torch.nn.Linear(6,3)\n",
    "        self.l3 = torch.nn.Linear(3, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    # Feed forward class\n",
    "    def forward(self, X):\n",
    "        o1 = self.sigmoid(self.l1(X))\n",
    "        o2 = self.sigmoid(self.l2(o1))\n",
    "        \n",
    "        predict = self.sigmoid(self.l3(o2))\n",
    "        \n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5212a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_Model = Linear_nn()\n",
    " \n",
    "def train_model(epochs, learning_rate):\n",
    "    \n",
    "    # Better results with sum as the loss function\n",
    "    criterion = torch.nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    # Using adam as optimizer\n",
    "    optimizer = torch.optim.Adam(Linear_Model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    print(\"Starting model with {} Epochs and Learning Rate: {}\".format(epochs, learning_rate))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        predict = Linear_Model(X_train_torch.float())\n",
    "        loss = criterion(predict, y_train_torch.view(-1, 1).float())\n",
    "        \n",
    "        print(\"Epoch: {} | Loss: {} | Prediction: {}\".format(epoch, loss, predict[0]))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90cf21d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model with 200 Epochs and Learning Rate: 0.01\n",
      "Epoch: 0 | Loss: 415.36016845703125 | Prediction: tensor([0.4697], grad_fn=<SelectBackward0>)\n",
      "Epoch: 1 | Loss: 412.0970458984375 | Prediction: tensor([0.4618], grad_fn=<SelectBackward0>)\n",
      "Epoch: 2 | Loss: 409.0989685058594 | Prediction: tensor([0.4542], grad_fn=<SelectBackward0>)\n",
      "Epoch: 3 | Loss: 406.3634338378906 | Prediction: tensor([0.4467], grad_fn=<SelectBackward0>)\n",
      "Epoch: 4 | Loss: 403.8838806152344 | Prediction: tensor([0.4394], grad_fn=<SelectBackward0>)\n",
      "Epoch: 5 | Loss: 401.650146484375 | Prediction: tensor([0.4325], grad_fn=<SelectBackward0>)\n",
      "Epoch: 6 | Loss: 399.6484680175781 | Prediction: tensor([0.4258], grad_fn=<SelectBackward0>)\n",
      "Epoch: 7 | Loss: 397.86236572265625 | Prediction: tensor([0.4194], grad_fn=<SelectBackward0>)\n",
      "Epoch: 8 | Loss: 396.2730407714844 | Prediction: tensor([0.4133], grad_fn=<SelectBackward0>)\n",
      "Epoch: 9 | Loss: 394.8607177734375 | Prediction: tensor([0.4075], grad_fn=<SelectBackward0>)\n",
      "Epoch: 10 | Loss: 393.6053466796875 | Prediction: tensor([0.4020], grad_fn=<SelectBackward0>)\n",
      "Epoch: 11 | Loss: 392.48736572265625 | Prediction: tensor([0.3968], grad_fn=<SelectBackward0>)\n",
      "Epoch: 12 | Loss: 391.4875183105469 | Prediction: tensor([0.3920], grad_fn=<SelectBackward0>)\n",
      "Epoch: 13 | Loss: 390.58721923828125 | Prediction: tensor([0.3876], grad_fn=<SelectBackward0>)\n",
      "Epoch: 14 | Loss: 389.76806640625 | Prediction: tensor([0.3834], grad_fn=<SelectBackward0>)\n",
      "Epoch: 15 | Loss: 389.01177978515625 | Prediction: tensor([0.3796], grad_fn=<SelectBackward0>)\n",
      "Epoch: 16 | Loss: 388.2998352050781 | Prediction: tensor([0.3761], grad_fn=<SelectBackward0>)\n",
      "Epoch: 17 | Loss: 387.6140441894531 | Prediction: tensor([0.3730], grad_fn=<SelectBackward0>)\n",
      "Epoch: 18 | Loss: 386.9363098144531 | Prediction: tensor([0.3702], grad_fn=<SelectBackward0>)\n",
      "Epoch: 19 | Loss: 386.24932861328125 | Prediction: tensor([0.3677], grad_fn=<SelectBackward0>)\n",
      "Epoch: 20 | Loss: 385.5366516113281 | Prediction: tensor([0.3655], grad_fn=<SelectBackward0>)\n",
      "Epoch: 21 | Loss: 384.7832336425781 | Prediction: tensor([0.3636], grad_fn=<SelectBackward0>)\n",
      "Epoch: 22 | Loss: 383.9757385253906 | Prediction: tensor([0.3620], grad_fn=<SelectBackward0>)\n",
      "Epoch: 23 | Loss: 383.1026916503906 | Prediction: tensor([0.3606], grad_fn=<SelectBackward0>)\n",
      "Epoch: 24 | Loss: 382.1544189453125 | Prediction: tensor([0.3594], grad_fn=<SelectBackward0>)\n",
      "Epoch: 25 | Loss: 381.12322998046875 | Prediction: tensor([0.3585], grad_fn=<SelectBackward0>)\n",
      "Epoch: 26 | Loss: 380.0029602050781 | Prediction: tensor([0.3578], grad_fn=<SelectBackward0>)\n",
      "Epoch: 27 | Loss: 378.7890625 | Prediction: tensor([0.3572], grad_fn=<SelectBackward0>)\n",
      "Epoch: 28 | Loss: 377.47808837890625 | Prediction: tensor([0.3568], grad_fn=<SelectBackward0>)\n",
      "Epoch: 29 | Loss: 376.0675354003906 | Prediction: tensor([0.3565], grad_fn=<SelectBackward0>)\n",
      "Epoch: 30 | Loss: 374.5553283691406 | Prediction: tensor([0.3563], grad_fn=<SelectBackward0>)\n",
      "Epoch: 31 | Loss: 372.9402160644531 | Prediction: tensor([0.3562], grad_fn=<SelectBackward0>)\n",
      "Epoch: 32 | Loss: 371.2209167480469 | Prediction: tensor([0.3561], grad_fn=<SelectBackward0>)\n",
      "Epoch: 33 | Loss: 369.3963317871094 | Prediction: tensor([0.3561], grad_fn=<SelectBackward0>)\n",
      "Epoch: 34 | Loss: 367.4654541015625 | Prediction: tensor([0.3561], grad_fn=<SelectBackward0>)\n",
      "Epoch: 35 | Loss: 365.42742919921875 | Prediction: tensor([0.3561], grad_fn=<SelectBackward0>)\n",
      "Epoch: 36 | Loss: 363.2813720703125 | Prediction: tensor([0.3560], grad_fn=<SelectBackward0>)\n",
      "Epoch: 37 | Loss: 361.0268859863281 | Prediction: tensor([0.3560], grad_fn=<SelectBackward0>)\n",
      "Epoch: 38 | Loss: 358.66363525390625 | Prediction: tensor([0.3559], grad_fn=<SelectBackward0>)\n",
      "Epoch: 39 | Loss: 356.1917724609375 | Prediction: tensor([0.3557], grad_fn=<SelectBackward0>)\n",
      "Epoch: 40 | Loss: 353.6118469238281 | Prediction: tensor([0.3555], grad_fn=<SelectBackward0>)\n",
      "Epoch: 41 | Loss: 350.9249267578125 | Prediction: tensor([0.3552], grad_fn=<SelectBackward0>)\n",
      "Epoch: 42 | Loss: 348.13250732421875 | Prediction: tensor([0.3548], grad_fn=<SelectBackward0>)\n",
      "Epoch: 43 | Loss: 345.23651123046875 | Prediction: tensor([0.3543], grad_fn=<SelectBackward0>)\n",
      "Epoch: 44 | Loss: 342.2394104003906 | Prediction: tensor([0.3537], grad_fn=<SelectBackward0>)\n",
      "Epoch: 45 | Loss: 339.1439514160156 | Prediction: tensor([0.3530], grad_fn=<SelectBackward0>)\n",
      "Epoch: 46 | Loss: 335.953369140625 | Prediction: tensor([0.3522], grad_fn=<SelectBackward0>)\n",
      "Epoch: 47 | Loss: 332.6712646484375 | Prediction: tensor([0.3513], grad_fn=<SelectBackward0>)\n",
      "Epoch: 48 | Loss: 329.3017578125 | Prediction: tensor([0.3503], grad_fn=<SelectBackward0>)\n",
      "Epoch: 49 | Loss: 325.84912109375 | Prediction: tensor([0.3492], grad_fn=<SelectBackward0>)\n",
      "Epoch: 50 | Loss: 322.31829833984375 | Prediction: tensor([0.3479], grad_fn=<SelectBackward0>)\n",
      "Epoch: 51 | Loss: 318.71441650390625 | Prediction: tensor([0.3465], grad_fn=<SelectBackward0>)\n",
      "Epoch: 52 | Loss: 315.0431213378906 | Prediction: tensor([0.3450], grad_fn=<SelectBackward0>)\n",
      "Epoch: 53 | Loss: 311.3104248046875 | Prediction: tensor([0.3434], grad_fn=<SelectBackward0>)\n",
      "Epoch: 54 | Loss: 307.5228576660156 | Prediction: tensor([0.3417], grad_fn=<SelectBackward0>)\n",
      "Epoch: 55 | Loss: 303.6871337890625 | Prediction: tensor([0.3398], grad_fn=<SelectBackward0>)\n",
      "Epoch: 56 | Loss: 299.8103942871094 | Prediction: tensor([0.3379], grad_fn=<SelectBackward0>)\n",
      "Epoch: 57 | Loss: 295.900146484375 | Prediction: tensor([0.3358], grad_fn=<SelectBackward0>)\n",
      "Epoch: 58 | Loss: 291.9639892578125 | Prediction: tensor([0.3337], grad_fn=<SelectBackward0>)\n",
      "Epoch: 59 | Loss: 288.0096740722656 | Prediction: tensor([0.3314], grad_fn=<SelectBackward0>)\n",
      "Epoch: 60 | Loss: 284.0450744628906 | Prediction: tensor([0.3291], grad_fn=<SelectBackward0>)\n",
      "Epoch: 61 | Loss: 280.0780029296875 | Prediction: tensor([0.3267], grad_fn=<SelectBackward0>)\n",
      "Epoch: 62 | Loss: 276.11614990234375 | Prediction: tensor([0.3242], grad_fn=<SelectBackward0>)\n",
      "Epoch: 63 | Loss: 272.1670837402344 | Prediction: tensor([0.3216], grad_fn=<SelectBackward0>)\n",
      "Epoch: 64 | Loss: 268.23809814453125 | Prediction: tensor([0.3190], grad_fn=<SelectBackward0>)\n",
      "Epoch: 65 | Loss: 264.33612060546875 | Prediction: tensor([0.3163], grad_fn=<SelectBackward0>)\n",
      "Epoch: 66 | Loss: 260.4677429199219 | Prediction: tensor([0.3136], grad_fn=<SelectBackward0>)\n",
      "Epoch: 67 | Loss: 256.63916015625 | Prediction: tensor([0.3108], grad_fn=<SelectBackward0>)\n",
      "Epoch: 68 | Loss: 252.85597229003906 | Prediction: tensor([0.3079], grad_fn=<SelectBackward0>)\n",
      "Epoch: 69 | Loss: 249.12342834472656 | Prediction: tensor([0.3051], grad_fn=<SelectBackward0>)\n",
      "Epoch: 70 | Loss: 245.4461212158203 | Prediction: tensor([0.3022], grad_fn=<SelectBackward0>)\n",
      "Epoch: 71 | Loss: 241.82823181152344 | Prediction: tensor([0.2993], grad_fn=<SelectBackward0>)\n",
      "Epoch: 72 | Loss: 238.27320861816406 | Prediction: tensor([0.2963], grad_fn=<SelectBackward0>)\n",
      "Epoch: 73 | Loss: 234.7841796875 | Prediction: tensor([0.2934], grad_fn=<SelectBackward0>)\n",
      "Epoch: 74 | Loss: 231.36358642578125 | Prediction: tensor([0.2904], grad_fn=<SelectBackward0>)\n",
      "Epoch: 75 | Loss: 228.01344299316406 | Prediction: tensor([0.2875], grad_fn=<SelectBackward0>)\n",
      "Epoch: 76 | Loss: 224.7352294921875 | Prediction: tensor([0.2845], grad_fn=<SelectBackward0>)\n",
      "Epoch: 77 | Loss: 221.52999877929688 | Prediction: tensor([0.2815], grad_fn=<SelectBackward0>)\n",
      "Epoch: 78 | Loss: 218.3984375 | Prediction: tensor([0.2785], grad_fn=<SelectBackward0>)\n",
      "Epoch: 79 | Loss: 215.34075927734375 | Prediction: tensor([0.2756], grad_fn=<SelectBackward0>)\n",
      "Epoch: 80 | Loss: 212.35690307617188 | Prediction: tensor([0.2726], grad_fn=<SelectBackward0>)\n",
      "Epoch: 81 | Loss: 209.4464874267578 | Prediction: tensor([0.2697], grad_fn=<SelectBackward0>)\n",
      "Epoch: 82 | Loss: 206.6088409423828 | Prediction: tensor([0.2667], grad_fn=<SelectBackward0>)\n",
      "Epoch: 83 | Loss: 203.84310913085938 | Prediction: tensor([0.2638], grad_fn=<SelectBackward0>)\n",
      "Epoch: 84 | Loss: 201.14825439453125 | Prediction: tensor([0.2609], grad_fn=<SelectBackward0>)\n",
      "Epoch: 85 | Loss: 198.52294921875 | Prediction: tensor([0.2581], grad_fn=<SelectBackward0>)\n",
      "Epoch: 86 | Loss: 195.96585083007812 | Prediction: tensor([0.2552], grad_fn=<SelectBackward0>)\n",
      "Epoch: 87 | Loss: 193.47544860839844 | Prediction: tensor([0.2524], grad_fn=<SelectBackward0>)\n",
      "Epoch: 88 | Loss: 191.0501708984375 | Prediction: tensor([0.2496], grad_fn=<SelectBackward0>)\n",
      "Epoch: 89 | Loss: 188.68826293945312 | Prediction: tensor([0.2468], grad_fn=<SelectBackward0>)\n",
      "Epoch: 90 | Loss: 186.3881378173828 | Prediction: tensor([0.2441], grad_fn=<SelectBackward0>)\n",
      "Epoch: 91 | Loss: 184.1479034423828 | Prediction: tensor([0.2414], grad_fn=<SelectBackward0>)\n",
      "Epoch: 92 | Loss: 181.9658660888672 | Prediction: tensor([0.2387], grad_fn=<SelectBackward0>)\n",
      "Epoch: 93 | Loss: 179.8402099609375 | Prediction: tensor([0.2361], grad_fn=<SelectBackward0>)\n",
      "Epoch: 94 | Loss: 177.76910400390625 | Prediction: tensor([0.2335], grad_fn=<SelectBackward0>)\n",
      "Epoch: 95 | Loss: 175.75079345703125 | Prediction: tensor([0.2309], grad_fn=<SelectBackward0>)\n",
      "Epoch: 96 | Loss: 173.78350830078125 | Prediction: tensor([0.2284], grad_fn=<SelectBackward0>)\n",
      "Epoch: 97 | Loss: 171.865478515625 | Prediction: tensor([0.2259], grad_fn=<SelectBackward0>)\n",
      "Epoch: 98 | Loss: 169.9950714111328 | Prediction: tensor([0.2234], grad_fn=<SelectBackward0>)\n",
      "Epoch: 99 | Loss: 168.1705780029297 | Prediction: tensor([0.2210], grad_fn=<SelectBackward0>)\n",
      "Epoch: 100 | Loss: 166.39039611816406 | Prediction: tensor([0.2186], grad_fn=<SelectBackward0>)\n",
      "Epoch: 101 | Loss: 164.65292358398438 | Prediction: tensor([0.2163], grad_fn=<SelectBackward0>)\n",
      "Epoch: 102 | Loss: 162.95672607421875 | Prediction: tensor([0.2139], grad_fn=<SelectBackward0>)\n",
      "Epoch: 103 | Loss: 161.30027770996094 | Prediction: tensor([0.2117], grad_fn=<SelectBackward0>)\n",
      "Epoch: 104 | Loss: 159.68222045898438 | Prediction: tensor([0.2094], grad_fn=<SelectBackward0>)\n",
      "Epoch: 105 | Loss: 158.10125732421875 | Prediction: tensor([0.2072], grad_fn=<SelectBackward0>)\n",
      "Epoch: 106 | Loss: 156.55604553222656 | Prediction: tensor([0.2051], grad_fn=<SelectBackward0>)\n",
      "Epoch: 107 | Loss: 155.04542541503906 | Prediction: tensor([0.2029], grad_fn=<SelectBackward0>)\n",
      "Epoch: 108 | Loss: 153.56822204589844 | Prediction: tensor([0.2008], grad_fn=<SelectBackward0>)\n",
      "Epoch: 109 | Loss: 152.1233673095703 | Prediction: tensor([0.1988], grad_fn=<SelectBackward0>)\n",
      "Epoch: 110 | Loss: 150.70982360839844 | Prediction: tensor([0.1967], grad_fn=<SelectBackward0>)\n",
      "Epoch: 111 | Loss: 149.32659912109375 | Prediction: tensor([0.1948], grad_fn=<SelectBackward0>)\n",
      "Epoch: 112 | Loss: 147.97276306152344 | Prediction: tensor([0.1928], grad_fn=<SelectBackward0>)\n",
      "Epoch: 113 | Loss: 146.6474151611328 | Prediction: tensor([0.1909], grad_fn=<SelectBackward0>)\n",
      "Epoch: 114 | Loss: 145.34974670410156 | Prediction: tensor([0.1890], grad_fn=<SelectBackward0>)\n",
      "Epoch: 115 | Loss: 144.07888793945312 | Prediction: tensor([0.1871], grad_fn=<SelectBackward0>)\n",
      "Epoch: 116 | Loss: 142.83413696289062 | Prediction: tensor([0.1853], grad_fn=<SelectBackward0>)\n",
      "Epoch: 117 | Loss: 141.6147003173828 | Prediction: tensor([0.1835], grad_fn=<SelectBackward0>)\n",
      "Epoch: 118 | Loss: 140.41990661621094 | Prediction: tensor([0.1817], grad_fn=<SelectBackward0>)\n",
      "Epoch: 119 | Loss: 139.2490692138672 | Prediction: tensor([0.1800], grad_fn=<SelectBackward0>)\n",
      "Epoch: 120 | Loss: 138.10153198242188 | Prediction: tensor([0.1783], grad_fn=<SelectBackward0>)\n",
      "Epoch: 121 | Loss: 136.9766845703125 | Prediction: tensor([0.1766], grad_fn=<SelectBackward0>)\n",
      "Epoch: 122 | Loss: 135.8739013671875 | Prediction: tensor([0.1749], grad_fn=<SelectBackward0>)\n",
      "Epoch: 123 | Loss: 134.79263305664062 | Prediction: tensor([0.1733], grad_fn=<SelectBackward0>)\n",
      "Epoch: 124 | Loss: 133.7322540283203 | Prediction: tensor([0.1717], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125 | Loss: 132.69229125976562 | Prediction: tensor([0.1701], grad_fn=<SelectBackward0>)\n",
      "Epoch: 126 | Loss: 131.6721954345703 | Prediction: tensor([0.1686], grad_fn=<SelectBackward0>)\n",
      "Epoch: 127 | Loss: 130.6714630126953 | Prediction: tensor([0.1670], grad_fn=<SelectBackward0>)\n",
      "Epoch: 128 | Loss: 129.6896209716797 | Prediction: tensor([0.1655], grad_fn=<SelectBackward0>)\n",
      "Epoch: 129 | Loss: 128.72616577148438 | Prediction: tensor([0.1641], grad_fn=<SelectBackward0>)\n",
      "Epoch: 130 | Loss: 127.78067016601562 | Prediction: tensor([0.1626], grad_fn=<SelectBackward0>)\n",
      "Epoch: 131 | Loss: 126.8526840209961 | Prediction: tensor([0.1612], grad_fn=<SelectBackward0>)\n",
      "Epoch: 132 | Loss: 125.9417953491211 | Prediction: tensor([0.1597], grad_fn=<SelectBackward0>)\n",
      "Epoch: 133 | Loss: 125.04757690429688 | Prediction: tensor([0.1583], grad_fn=<SelectBackward0>)\n",
      "Epoch: 134 | Loss: 124.16964721679688 | Prediction: tensor([0.1570], grad_fn=<SelectBackward0>)\n",
      "Epoch: 135 | Loss: 123.30760192871094 | Prediction: tensor([0.1556], grad_fn=<SelectBackward0>)\n",
      "Epoch: 136 | Loss: 122.46109008789062 | Prediction: tensor([0.1543], grad_fn=<SelectBackward0>)\n",
      "Epoch: 137 | Loss: 121.62975311279297 | Prediction: tensor([0.1530], grad_fn=<SelectBackward0>)\n",
      "Epoch: 138 | Loss: 120.81321716308594 | Prediction: tensor([0.1517], grad_fn=<SelectBackward0>)\n",
      "Epoch: 139 | Loss: 120.01117706298828 | Prediction: tensor([0.1504], grad_fn=<SelectBackward0>)\n",
      "Epoch: 140 | Loss: 119.22327423095703 | Prediction: tensor([0.1491], grad_fn=<SelectBackward0>)\n",
      "Epoch: 141 | Loss: 118.44918823242188 | Prediction: tensor([0.1479], grad_fn=<SelectBackward0>)\n",
      "Epoch: 142 | Loss: 117.68862915039062 | Prediction: tensor([0.1466], grad_fn=<SelectBackward0>)\n",
      "Epoch: 143 | Loss: 116.9412612915039 | Prediction: tensor([0.1454], grad_fn=<SelectBackward0>)\n",
      "Epoch: 144 | Loss: 116.20677947998047 | Prediction: tensor([0.1442], grad_fn=<SelectBackward0>)\n",
      "Epoch: 145 | Loss: 115.48493957519531 | Prediction: tensor([0.1430], grad_fn=<SelectBackward0>)\n",
      "Epoch: 146 | Loss: 114.77540588378906 | Prediction: tensor([0.1419], grad_fn=<SelectBackward0>)\n",
      "Epoch: 147 | Loss: 114.07791900634766 | Prediction: tensor([0.1407], grad_fn=<SelectBackward0>)\n",
      "Epoch: 148 | Loss: 113.39219665527344 | Prediction: tensor([0.1396], grad_fn=<SelectBackward0>)\n",
      "Epoch: 149 | Loss: 112.71795654296875 | Prediction: tensor([0.1385], grad_fn=<SelectBackward0>)\n",
      "Epoch: 150 | Loss: 112.05496215820312 | Prediction: tensor([0.1373], grad_fn=<SelectBackward0>)\n",
      "Epoch: 151 | Loss: 111.40293884277344 | Prediction: tensor([0.1362], grad_fn=<SelectBackward0>)\n",
      "Epoch: 152 | Loss: 110.7616195678711 | Prediction: tensor([0.1352], grad_fn=<SelectBackward0>)\n",
      "Epoch: 153 | Loss: 110.13079833984375 | Prediction: tensor([0.1341], grad_fn=<SelectBackward0>)\n",
      "Epoch: 154 | Loss: 109.51019287109375 | Prediction: tensor([0.1330], grad_fn=<SelectBackward0>)\n",
      "Epoch: 155 | Loss: 108.89961242675781 | Prediction: tensor([0.1320], grad_fn=<SelectBackward0>)\n",
      "Epoch: 156 | Loss: 108.29878997802734 | Prediction: tensor([0.1309], grad_fn=<SelectBackward0>)\n",
      "Epoch: 157 | Loss: 107.70752716064453 | Prediction: tensor([0.1299], grad_fn=<SelectBackward0>)\n",
      "Epoch: 158 | Loss: 107.12562561035156 | Prediction: tensor([0.1289], grad_fn=<SelectBackward0>)\n",
      "Epoch: 159 | Loss: 106.55284881591797 | Prediction: tensor([0.1279], grad_fn=<SelectBackward0>)\n",
      "Epoch: 160 | Loss: 105.98902130126953 | Prediction: tensor([0.1269], grad_fn=<SelectBackward0>)\n",
      "Epoch: 161 | Loss: 105.43391418457031 | Prediction: tensor([0.1259], grad_fn=<SelectBackward0>)\n",
      "Epoch: 162 | Loss: 104.88736724853516 | Prediction: tensor([0.1249], grad_fn=<SelectBackward0>)\n",
      "Epoch: 163 | Loss: 104.34918975830078 | Prediction: tensor([0.1240], grad_fn=<SelectBackward0>)\n",
      "Epoch: 164 | Loss: 103.81917572021484 | Prediction: tensor([0.1230], grad_fn=<SelectBackward0>)\n",
      "Epoch: 165 | Loss: 103.29714965820312 | Prediction: tensor([0.1220], grad_fn=<SelectBackward0>)\n",
      "Epoch: 166 | Loss: 102.78296661376953 | Prediction: tensor([0.1211], grad_fn=<SelectBackward0>)\n",
      "Epoch: 167 | Loss: 102.27643585205078 | Prediction: tensor([0.1202], grad_fn=<SelectBackward0>)\n",
      "Epoch: 168 | Loss: 101.77739715576172 | Prediction: tensor([0.1192], grad_fn=<SelectBackward0>)\n",
      "Epoch: 169 | Loss: 101.28565216064453 | Prediction: tensor([0.1183], grad_fn=<SelectBackward0>)\n",
      "Epoch: 170 | Loss: 100.80110168457031 | Prediction: tensor([0.1174], grad_fn=<SelectBackward0>)\n",
      "Epoch: 171 | Loss: 100.32353210449219 | Prediction: tensor([0.1165], grad_fn=<SelectBackward0>)\n",
      "Epoch: 172 | Loss: 99.85282897949219 | Prediction: tensor([0.1156], grad_fn=<SelectBackward0>)\n",
      "Epoch: 173 | Loss: 99.3888168334961 | Prediction: tensor([0.1148], grad_fn=<SelectBackward0>)\n",
      "Epoch: 174 | Loss: 98.93136596679688 | Prediction: tensor([0.1139], grad_fn=<SelectBackward0>)\n",
      "Epoch: 175 | Loss: 98.48033142089844 | Prediction: tensor([0.1130], grad_fn=<SelectBackward0>)\n",
      "Epoch: 176 | Loss: 98.03558349609375 | Prediction: tensor([0.1122], grad_fn=<SelectBackward0>)\n",
      "Epoch: 177 | Loss: 97.59696960449219 | Prediction: tensor([0.1113], grad_fn=<SelectBackward0>)\n",
      "Epoch: 178 | Loss: 97.16437530517578 | Prediction: tensor([0.1105], grad_fn=<SelectBackward0>)\n",
      "Epoch: 179 | Loss: 96.73767852783203 | Prediction: tensor([0.1097], grad_fn=<SelectBackward0>)\n",
      "Epoch: 180 | Loss: 96.31674194335938 | Prediction: tensor([0.1088], grad_fn=<SelectBackward0>)\n",
      "Epoch: 181 | Loss: 95.90148162841797 | Prediction: tensor([0.1080], grad_fn=<SelectBackward0>)\n",
      "Epoch: 182 | Loss: 95.49175262451172 | Prediction: tensor([0.1072], grad_fn=<SelectBackward0>)\n",
      "Epoch: 183 | Loss: 95.08747100830078 | Prediction: tensor([0.1064], grad_fn=<SelectBackward0>)\n",
      "Epoch: 184 | Loss: 94.68852233886719 | Prediction: tensor([0.1056], grad_fn=<SelectBackward0>)\n",
      "Epoch: 185 | Loss: 94.29481506347656 | Prediction: tensor([0.1049], grad_fn=<SelectBackward0>)\n",
      "Epoch: 186 | Loss: 93.90623474121094 | Prediction: tensor([0.1041], grad_fn=<SelectBackward0>)\n",
      "Epoch: 187 | Loss: 93.52269744873047 | Prediction: tensor([0.1033], grad_fn=<SelectBackward0>)\n",
      "Epoch: 188 | Loss: 93.14411926269531 | Prediction: tensor([0.1026], grad_fn=<SelectBackward0>)\n",
      "Epoch: 189 | Loss: 92.77040100097656 | Prediction: tensor([0.1019], grad_fn=<SelectBackward0>)\n",
      "Epoch: 190 | Loss: 92.40145111083984 | Prediction: tensor([0.1011], grad_fn=<SelectBackward0>)\n",
      "Epoch: 191 | Loss: 92.03718566894531 | Prediction: tensor([0.1004], grad_fn=<SelectBackward0>)\n",
      "Epoch: 192 | Loss: 91.67753601074219 | Prediction: tensor([0.0997], grad_fn=<SelectBackward0>)\n",
      "Epoch: 193 | Loss: 91.3224105834961 | Prediction: tensor([0.0990], grad_fn=<SelectBackward0>)\n",
      "Epoch: 194 | Loss: 90.97171783447266 | Prediction: tensor([0.0983], grad_fn=<SelectBackward0>)\n",
      "Epoch: 195 | Loss: 90.62538146972656 | Prediction: tensor([0.0976], grad_fn=<SelectBackward0>)\n",
      "Epoch: 196 | Loss: 90.2833480834961 | Prediction: tensor([0.0969], grad_fn=<SelectBackward0>)\n",
      "Epoch: 197 | Loss: 89.94552612304688 | Prediction: tensor([0.0962], grad_fn=<SelectBackward0>)\n",
      "Epoch: 198 | Loss: 89.61183166503906 | Prediction: tensor([0.0956], grad_fn=<SelectBackward0>)\n",
      "Epoch: 199 | Loss: 89.28221893310547 | Prediction: tensor([0.0949], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_model(200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b1ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict X_test as a tensor\n",
    "y_predicted = Linear_Model.double().forward(X_test_torch) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68f73362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted truth and ground truth\n",
    "\n",
    "PT = y_predicted.numpy()\n",
    "GT = y_test_torch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "670dd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ground truth and prediction \n",
    "def get_results(GT, PT):\n",
    "    # True positive\n",
    "    TP = 0\n",
    "    # False positive\n",
    "    FP = 0\n",
    "    # False negative\n",
    "    FN = 0\n",
    "    # True negative\n",
    "    TN = 0\n",
    "    \n",
    "    for n in range(len(GT)):\n",
    "        if GT[n] == 1 and PT[n] == True:\n",
    "            TP += 1\n",
    "        elif GT[n] == 0 and PT[n] == True:\n",
    "            FP += 1\n",
    "        elif GT[n] == 1 and PT[n] == False:\n",
    "            FN += 1\n",
    "        elif GT[n] == 0 and PT[n] == False:\n",
    "            TN += 1\n",
    "    accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = (2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    print(\"--- Results -----------------\")\n",
    "    print(\"True Positives: {}\".format(TP))\n",
    "    print(\"False Positives: {}\".format(FP))\n",
    "    print(\"False Negatives: {}\".format(FN))\n",
    "    print(\"True Negatives: {}\".format(TN))\n",
    "    print(\"\\nAccuracy: {}\".format(accuracy))\n",
    "    print(\"\\nPrecision: {}\".format(precision))\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "    print(\"F1 score: {}\".format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c167861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results -----------------\n",
      "True Positives: 29\n",
      "False Positives: 1\n",
      "False Negatives: 0\n",
      "True Negatives: 39\n",
      "\n",
      "Accuracy: 0.9855072463768116\n",
      "\n",
      "Precision: 0.9666666666666667\n",
      "Recall: 1.0\n",
      "F1 score: 0.983050847457627\n"
     ]
    }
   ],
   "source": [
    "get_results(PT, GT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
